{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f4bb70",
   "metadata": {},
   "source": [
    "# üîÑ Refresh Dataset from NASA Exoplanet Archive  \n",
    "This section downloads the **latest Kepler KOI dataset** directly from the NASA Exoplanet Archive (Q1‚ÄìQ17 DR25),  \n",
    "renames columns to match our project, creates target labels, and saves fresh `train`/`test` splits.  \n",
    "\n",
    "‚û°Ô∏è The outputs will replace the old files:  \n",
    "- train.csv, test.csv, test_solution.csv  \n",
    "- train2.csv, test2.csv, test_solution2.csv  \n",
    "\n",
    "These files will then be used by `modified_model.ipynb` for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5440a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Setup: folders & imports ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = Path(\"data/raw\")\n",
    "OUT_DIR  = Path(\"data/processed\")  # keep outputs where your project expects them\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# NASA TAP CSV URL for KOI Q1‚ÄìQ17 DR25 delivery\n",
    "KOI_URL = (\n",
    "    \"https://exoplanetarchive.ipac.caltech.edu/TAP/sync\"\n",
    "    \"?query=select+*+from+q1_q17_dr25_koi&format=csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b129cd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Download the latest KOI table via TAP into a DataFrame ---\n",
    "raw = pd.read_csv(KOI_URL, low_memory=False)\n",
    "raw.to_csv(DATA_DIR / \"exoplanets_latest_raw.csv\", index=False)\n",
    "print(raw.shape)\n",
    "raw.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0264c84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Exact renaming to match your existing notebooks ---\n",
    "rename_map = {\n",
    "'kepid':'KepID',\n",
    "    'kepoi_name':'KOIName',\n",
    "    'kepler_name':'KeplerName',\n",
    "    'koi_disposition':'ExoplanetArchiveDisposition',\n",
    "    'koi_pdisposition':'DispositionUsingKeplerData',\n",
    "    'koi_score':'DispositionScore',\n",
    "    'koi_fpflag_nt':'NotTransitLikeFlag',\n",
    "    'koi_fpflag_ss':'StellarEclipseFlag',\n",
    "    'koi_fpflag_co':'CentroidOffsetFlag',\n",
    "    'koi_fpflag_ec':'EphemerisMatchFlag',\n",
    "    'koi_period':'OrbitalPeriod[days]',\n",
    "    'koi_period_err1':'OrbitalPeriodUpperUnc[days]',\n",
    "    'koi_period_err2':'OrbitalPeriodLowerUnc[days]',\n",
    "    'koi_time0bk':'TransitEpoch[BKJD]',\n",
    "    'koi_time0bk_err1':'TransitEpochUpperUnc[BKJD]',\n",
    "    'koi_time0bk_err2':'TransitEpochLowerUnc[BKJD]',\n",
    "    'koi_impact':'ImpactParameter',\n",
    "    'koi_impact_err1':'ImpactParameterUpperUnc',\n",
    "    'koi_impact_err2':'ImpactParameterLowerUnc',\n",
    "    'koi_duration':'TransitDuration[hrs]',\n",
    "    'koi_duration_err1':'TransitDurationUpperUnc[hrs]',\n",
    "    'koi_duration_err2':'TransitDurationLowerUnc[hrs]',\n",
    "    'koi_depth':'TransitDepth[ppm]',\n",
    "    'koi_depth_err1':'TransitDepthUpperUnc[ppm]',\n",
    "    'koi_depth_err2':'TransitDepthLowerUnc[ppm]',\n",
    "    'koi_prad':'PlanetaryRadius[EarthRadii]',\n",
    "    'koi_prad_err1':'PlanetaryRadiusUpperUnc[EarthRadii]',\n",
    "    'koi_prad_err2':'PlanetaryRadiusLowerUnc[EarthRadii]',\n",
    "    'koi_teq':'EquilibriumTemperature[K]',\n",
    "    'koi_teq_err1':'EquilibriumTemperatureUpperUnc[K]',\n",
    "    'koi_teq_err2':'EquilibriumTemperatureLowerUnc[K]',\n",
    "    'koi_insol':'InsolationFlux[EarthFlux]',\n",
    "    'koi_insol_err1':'InsolationFluxUpperUnc[EarthFlux]',\n",
    "    'koi_insol_err2':'InsolationFluxLowerUnc[EarthFlux]',\n",
    "    'koi_model_snr':'TransitSNR',\n",
    "    'koi_tce_plnt_num':'TCEPlanetNumber',\n",
    "    'koi_tce_delivname':'TCEDeliver',\n",
    "    'koi_steff':'StellarTeff[K]',\n",
    "    'koi_steff_err1':'StellarTeffUpperUnc[K]',\n",
    "    'koi_steff_err2':'StellarTeffLowerUnc[K]',\n",
    "    'koi_slogg':'StellarLogg[cm/s^2]',\n",
    "    'koi_slogg_err1':'StellarLoggUpperUnc',\n",
    "    'koi_slogg_err2':'StellarLoggLowerUnc',\n",
    "    'koi_srad':'StellarRadius[SolRadii]',\n",
    "    'koi_srad_err1':'StellarRadiusUpperUnc[SolRadii]',\n",
    "    'koi_srad_err2':'StellarRadiusLowerUnc[SolRadii]',\n",
    "    'ra':'RA[deg]',\n",
    "    'dec':'Dec[deg]',\n",
    "    'koi_kepmag':'KeplerMag'\n",
    "}\n",
    "\n",
    "data = raw.rename(columns=rename_map)\n",
    "\n",
    "# Labels exactly like your project\n",
    "data['ExoplanetCandidate'] = data['DispositionUsingKeplerData'].apply(\n",
    "    lambda x: 1 if x == 'CANDIDATE' else 0\n",
    ")\n",
    "data['ExoplanetConfirmed'] = data['ExoplanetArchiveDisposition'].apply(\n",
    "    lambda x: 2 if x == 'CONFIRMED' else (1 if x == 'CANDIDATE' else 0)\n",
    ")\n",
    "\n",
    "# Drop the two disposition columns once labels are created\n",
    "data = data.drop(['ExoplanetArchiveDisposition', 'DispositionUsingKeplerData'], axis=1)\n",
    "\n",
    "# Drop name columns (you did this before)\n",
    "data.drop(columns=['KeplerName','KOIName'], inplace=True, errors='ignore')\n",
    "\n",
    "# Match your earlier pruning of these two uncertainty cols\n",
    "data = data.drop(['EquilibriumTemperatureUpperUnc.[K','EquilibriumTemperatureLowerUnc.[K'], axis=1, errors='ignore')\n",
    "\n",
    "# Remove rows with any remaining NaNs (same as you did)\n",
    "before = data.shape[0]\n",
    "data = data.dropna().copy()\n",
    "after = data.shape[0]\n",
    "\n",
    "# (Optional) coerce TCEDeliver to a numeric flag, exactly like your notebook\n",
    "if 'TCEDeliver' in data.columns:\n",
    "    data['TCEDeliver'] = 1\n",
    "\n",
    "print(f\"Rows before dropna: {before} | after: {after}\")\n",
    "print(data.shape)\n",
    "data.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d4ea2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(DATA_DIR / \"exoplanets_latest_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d68036",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- First split (for your original workflow) ---\n",
    "train, test = train_test_split(data, test_size=0.4, random_state=0)\n",
    "\n",
    "# Save the solution (labels) before dropping from features\n",
    "test_solution = test['ExoplanetCandidate'].copy()\n",
    "\n",
    "test_features = test.drop(['ExoplanetCandidate'], axis=1)\n",
    "\n",
    "# Save CSVs\n",
    "train.to_csv(OUT_DIR / \"train.csv\", index=False)\n",
    "test_features.to_csv(OUT_DIR / \"test.csv\", index=False)\n",
    "test_solution.to_csv(OUT_DIR / \"test_solution.csv\", index=False)\n",
    "\n",
    "len(train), len(test_features), len(test_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187d7f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Second split (to mirror your modified_model.ipynb) ---\n",
    "train2, test2 = train_test_split(data, test_size=0.4, random_state=1)\n",
    "\n",
    "test_solution2 = test2['ExoplanetCandidate'].copy()\n",
    "test2_features = test2.drop(['ExoplanetCandidate'], axis=1)\n",
    "\n",
    "# Save CSVs\n",
    "train2.to_csv(OUT_DIR / \"train2.csv\", index=False)\n",
    "test2_features.to_csv(OUT_DIR / \"test2.csv\", index=False)\n",
    "test_solution2.to_csv(OUT_DIR / \"test_solution2.csv\", index=False)\n",
    "\n",
    "len(train2), len(test2_features), len(test_solution2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153355a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Unique TCEDeliver values:\", data['TCEDeliver'].unique()[:5])\n",
    "print(\"ExoplanetCandidate value counts:\\n\", data['ExoplanetCandidate'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25621275",
   "metadata": {},
   "source": [
    "# ‚úÖ Dataset Ready  \n",
    "We now have updated training and testing files (`train.csv`, `test.csv`, `train2.csv`, etc.)  \n",
    "built from the **most up-to-date NASA KOI archive**.  \n",
    "\n",
    "The next section (old preprocessing code) is kept for reference but is no longer required  \n",
    "since we now start with cleaned, labeled splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922847b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"data/raw/exoplanets_2025.csv\")\n",
    "\n",
    "# Rename columns (shorten long names)\n",
    "data = data.rename(columns={\n",
    "    'kepid':'KepID',\n",
    "    'kepoi_name':'KOIName',\n",
    "    'kepler_name':'KeplerName',\n",
    "    'koi_disposition':'ExoplanetArchiveDisposition',\n",
    "    'koi_pdisposition':'DispositionUsingKeplerData',\n",
    "    'koi_score':'DispositionScore',\n",
    "    'koi_fpflag_nt':'NotTransit-LikeFalsePositiveFlag',\n",
    "    'koi_fpflag_ss':'StellarEclipseFalsePositiveFlag',\n",
    "    'koi_fpflag_co':'CentroidOffsetFalsePositiveFlag',\n",
    "    'koi_fpflag_ec':'EphemerisMatchIndicatesContaminationFalsePositiveFlag',\n",
    "    'koi_period':'OrbitalPeriod[days]',\n",
    "    'koi_time0bk':'TransitEpoch[BKJD]',\n",
    "    'koi_impact':'ImpactParameter',\n",
    "    'koi_duration':'TransitDuration[hrs]',\n",
    "    'koi_depth':'TransitDepth[ppm]',\n",
    "    'koi_prad':'PlanetaryRadius[Earthradii]',\n",
    "    'koi_teq':'EquilibriumTemperature[K]',\n",
    "    'koi_insol':'InsolationFlux[Earthflux]',\n",
    "    'koi_model_snr':'TransitSignal-to-Noise',\n",
    "    'koi_tce_plnt_num':'TCEPlanetNumber',\n",
    "    'koi_tce_delivname':'TCEDeliver',\n",
    "    'koi_steff':'StellarEffectiveTemperature[K]',\n",
    "    'koi_slogg':'StellarSurfaceGravity[log10(cm/s**2)]',\n",
    "    'koi_srad':'StellarRadius[Solarradii]',\n",
    "    'ra':'RA[decimaldegrees]',\n",
    "    'dec':'Dec[decimaldegrees]',\n",
    "    'koi_kepmag':'Kepler-band[mag]'\n",
    "})\n",
    "\n",
    "# Create target columns\n",
    "data['ExoplanetCandidate'] = data['DispositionUsingKeplerData'].apply(lambda x: 1 if x == 'CANDIDATE' else 0)\n",
    "data['ExoplanetConfirmed'] = data['ExoplanetArchiveDisposition'].apply(\n",
    "    lambda x: 2 if x == 'CONFIRMED' else 1 if x == 'CANDIDATE' else 0\n",
    ")\n",
    "\n",
    "# Drop unused columns\n",
    "data.drop(columns=['ExoplanetArchiveDisposition','DispositionUsingKeplerData','KeplerName','KOIName'], inplace=True)\n",
    "\n",
    "# Drop missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Split into train/test\n",
    "train, test = train_test_split(data, test_size=0.4, random_state=1)\n",
    "\n",
    "# Save splits\n",
    "train.to_csv(\"data/processed/train2.csv\", index=False)\n",
    "test.to_csv(\"data/processed/test2.csv\", index=False)\n",
    "\n",
    "# Save solutions separately\n",
    "test_solution = test[['ExoplanetCandidate']]\n",
    "test_solution.to_csv(\"data/processed/test_solution2.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete: train2.csv, test2.csv, test_solution2.csv saved\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
